## golang的调度

* [理解golang调度之一 ：操作系统调度](https://juejin.im/post/5cdeb6cdf265da1bd605727f)
* [理解golang调度之二 ：Go调度器](https://juejin.im/post/5ce11a39f265da1baf7cbc61)
* [理解golang调度之三：并发](https://juejin.im/post/5ce2a17fe51d45105e02120b)
* 《面向信仰编程》 [6.5 调度器](https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-goroutine/#651-%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86)
* [【Go 夜读】第 12 期 golang 中 goroutine 的调度](https://studygolang.com/topics/10860)
* []()
* []()
* []()

## 一、操作系统调度

### 1.1 操作系统调度器
操作系统调度器十分复杂，它必须要考虑到它所运行的底层硬件层级结构，包括但不限于处理器数和内核数，cpu cache和NUMA(非统一内存访问架构)。如果不考虑这些因素，调度器就没办法尽可能有效的工作。好事情是，你不必深入理解这些底层内容也能开发出好的程序。

你的程序其实就是一堆按顺序执行的机器指令。为了能让其正常干活，操作系统使用了线程的概念。线程会处理并执行分配给它的一系列的机器指令。线程会一直执行这些机器指令，直到没有指令再去给线程执行了。这也是为什么把线程称作"a path of execution"。

你运行的每个程序都会创建一个进程并且每个进程都会有一个初始线程。线程能够创建更多的线程。这些不同的线程独立运行并且调度行为是线程级别做决定的，而不是在进程级别。线程能够并发的执行(并发是说一个单独内核上每个线程会轮询占用一段cpu时间),而不是并行执行(在不同内核上同时执行)。线程同时会维持它自己的状态，并且能够在本地安全、独立地执行他自己的指令。这也说明了为什么线程是cpu调度的最小单位。

操作系统调度器，负责确保在有线程能够运行的时候内核不会空闲下来。它必须要制造出这样一种错觉——所有能够跑的线程此时都在同时执行。为了制造这种错觉，调度器需要优先执行高优先级的线程，但是它也必须保证低优先级的线程不会饿死(永远没有执行机会)。调度器也必须通过做出更聪明的决定将调度延时尽可能的压倒最少，。

幸运的是计算机发展了这么长时间，许多算法的应用使得调度器更加高效。为了能够理解上面的事情，需要解释一些重要的概念。

### 1.2执行指令
  程序计数器(PC)，有时候也叫做指令指针(IP)，能够让你找到下一个要执行的指令在哪。大部分的处理器里，PC指向下一个指令，而不是当前的指令。

### 1.3 线程状态
另一个重要概念就是“线程状态”，线程状态说明了调度器该如何处理此时的线程。线程有三个状态:等待、可运行、执行中。
* 等待(Waiting)：

 此时意味着线程停止并且等待被唤醒。可能发生的原因有，等待硬件(硬盘、网络)，操作系统(系统调用) 或者是同步调用(atomic,mutexes)。这些情况是导致性能问题的根源
*  可运行(Runnable)：

此时线程想要占用内核上的cpu时间来执行分配给线程的指令。如果你有许多线程想要cpu时间，线程必须要等一段时间才能取到cpu时间。随着更多线程争用cpu时间，线程分配的cpu时间会更短。这种情况下的调度延时也会造成性能问题。
*  执行中(Executing):

此时线程已经置于内核中，并且正在执行它的机器指令。应用程序的相关内容正在被处理。这种状态是我们所希望的

### 1.4 工作类型
线程有两种工作类型。第一种叫CPU密集型，第二种叫IO密集型
* CPU密集型(cpu-bound):

这种工作下，线程永远不会被置换到等待(waiting)状态。这种一般是进行持续性的cpu计算工作。比如计算Pi这种的就是cpu密集型工作
* IO密集型(io-bound)

这种工作会让线程进入到等待(waiting)状态。这种情况线程会持续的请求资源（比如网络资源）或者是对操作系统进行系统调用。线程需要访问数据库的情况就是IO密集型工作。同时我会把同步事件(例如mutexes、atomic)，这种需要线程等待的情况归入此类工作。
     
### 1.5 上下文切换(Context Switch)
在内核上切换线程的物理行为叫做上下文切换(context switch)。上下文切换发生在这样的情况，调度器从内核换下正在执行的线程，替换上可执行的线程。线程是从运行队列中取出，并设置成执行中(Executing)的状态。从内核上下来的线程会置成可运行状态,或者是等待状态。

上下文切换的代价是昂贵的，因为它需要花时间去交换线程，从内核上拿下来再放上去。上下文切换的延时受到很多因素影响，但是通常情况下，它会有1000--1500纳秒的延时。考虑到硬件上每个内核上平均每纳秒执行12个指令，一次上下文切换会花费你12k--18k个指令延时。这本质上来说，你的程序在上下文切换过程中失去了执行大量指令的机会。

如果你的程序集中于IO密集型(cpu-bound)的工作，上下文切换会相对有利。一旦一个线程进入到等待(waiting)状态。另一个处于可运行(Runnable)状态的线程会取代它的位置。这会使得内核始终是处于工作状态。这是调度器调度的一个重要方面，如果有事做(有线程处于可运行状态)就不允许内核闲下来。

### 1.6少即是多(Less Is More)

在早期时候，处理器仅仅只有一个内核，调度器并不十分复杂。因为你有一个单独的处理器，一个单独的内核，所以任何时间只能跑一个线程。处理方式是定义一个[调度期](https://lwn.net/Articles/404993/)(scheduler period) 然后尝试在一个调度期内去执行所有可运行(Runnable)的线程。这样没问题:把调度期按照需要执行的线程数量去分每一小段。

举例，如果你定义了你的调度期是10ms 并且你有两个线程，那每个线程会分到5ms。5个线程的话，每个线程就是2ms。但是如果你有100个线程会怎么样？每个线程时间片是10us(微秒), 这样就会无法工作，因为你需要大量时间去进行上下文切换(context switches)。

在另外一个场景，如果最小的时间切片是2ms 并且你有100个线程，调度期需要增加到2000ms也就是2s。要是如果你有1000个线程呢，现在调度期需要20s，也就是你要花20s才能跑完所有的线程如果每个线程都能跑满它的时间切片。

上面场景都是显而易见的事情。调度器在做决定的时候还要考虑到更多的因素。你控制了应用程序里的线程数量，当有更多线程的时候，并且是IO密集(IO-Bound)工作，就会有更多的混乱和不确定行为发生，调度和执行就花费更多时间。

这也是为什么说游戏规则就是“少即是多(Less is More)”，可运行线程越少意味着调度时间越少，线程得到的时间越多。更多的线程就意味着每个线程获得的时间就越少，分配的时间内做的事情也就越少。

### 1.7 找到平衡点

你需要在内核数和你的线程数量两者间，找到一个能够让你的程序获得最好吞吐量的平衡点。想要去找到这样的平衡点，线程池是一个很好的选择。

使用go之前，原作者在NT系统上使用C++和c#。在那个操作系统里，使用IOCP(IO Completion Ports) 线程池对于写多线程软件十分重要。作为一个工程师，你需要计算出你要用多少个线程池，以及每个线程池的最大线程数，从而在确定了内核数的系统里最大化你的吞吐量。

当写web服务时候，你需要和数据库通信。3是一个魔法数字，每个内核设置3个线程似乎在NT上有最好的吞吐量。换句话说，每内核3线程能够最小化上下文切换的延时，最大化在内核上的执行时间。当你创建一个IOPC线程池，我知道我可以在主机上设置每个内核1--3个线程数量。

如果我使用2个线程每个内核，完成工作的时间会变长，因为本来需要有工作去做的内核会有空闲时间。如果我每个内核用4个线程，也会花更长时间，因为我需要花更多时间进行上下文切换。平衡数字3，不管是什么原因，似乎在NT上都是一个神奇的数字。

当你的服务需要处理许多不同类型的工作会如何呢。那会有不同并且不一致的延迟。可能它会产生许多需要去处理的不同系统级别的事件。这种情况，你不可能去找到一个魔法数字，能让你在所有时间所有不同的工作情况下都有优秀的性能。当你使用线程池的时候，找到一个合适的配置会十分复杂。

### 1.8 缓存行(Cache Lines)

从主存访问数据有很高的延迟（大概100~300个时钟周期），因此处理器和内核会有缓存，能够让线程访问到更近的数据。从缓存访问数据的延迟非常低(大概3~40个时钟周期) 根据不同的缓存访问方式。衡量性能的一个方面就是，处理器通过减少数据访问延时而获取数据的效率。编写多线程的应用程序需要考虑到机器的缓存系统。



![img](https://user-gold-cdn.xitu.io/2019/5/17/16ac61a997fe6ead?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



处理器和主存使用缓存行(cache lines)进行数据交换。一个缓存行是一个64 byte的内存块，它在内存和缓存系统之间进行交换。每个内核会分配它自己需要的cache副本。这也是为什么多线程中的内存突变会造成严重的性能问题。

当多线程并行运行，正在访问相同数据，甚至是相邻的数据单元，他们会访问相同的缓存行。任何内核上运行的任何线程能够从相同的缓存行获取各自的拷贝。



![img](https://user-gold-cdn.xitu.io/2019/5/17/16ac61ad13385da9?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



如果内核上面的线程修改它的cache行副本，在硬件的操作下，同一cache行的所有其他副本都会被标记为无效。当一个线程尝试读写无效cache行，需要重新访问主存去获取新的cache行副本(大约要100~300个时钟周期)

也许在2核的处理器上这不是大问题，但是如果是一个32核处理器并行跑32个线程，并且同时访问和修改一个相同的cache行呢？由于处理器到处理器之间的通信延迟增加，情况会更糟。程序内存会发生颠簸，性能变得很差，而且很可能你也不知道问题的所在。

这就是[cache的一致性问题](https://youtu.be/WDIkqP4JbkE)（ cache-coherency problem ）或者是说是共享失败（false sharing）。当编写改变共享状态的多线程应用时，cache系统必须要考虑在内。

### 1.9 调度决策场景

思考一下下面的调度场景。

应用程序启动，主线程已经在core1上启动。当线程正在执行，它为了访问数据需要去检索cache行。主线程现在为了某些并发处理创建一个新的线程。那么问题来了。

一旦线程创建好，并且准备要运行了，那么调度器是否应该:

1. 从core1上换下主线程？这样做有助于提高性能，因为这个新线程需要的相同数据被缓存的可能性非常大。但是主线程并没有得到它的全部时间片。
2. 线程是否要一直等待直到main主线程完成它的时间后core1可用？线程并没有在运行，但是一旦运行它获取数据的延时将会消除。
3. 线程等待下一个可用的core？这意味着所选择的core的cache行会经历冲刷、检索、复制，从而导致延迟。但是线程会更快的启动，并且主线程会完成它的时间片。

以上都是调度器在做决定时需要考虑到的事情。

## 二、Go调度器

### 2.1 从一个程序开始

当你的go程序启动，主机上定义的每一个虚拟内核都会为它分配一个**逻辑处理器(P)**，如果你的处理器上每个物理内核有多个硬件线程（超线程），每个硬件线程对于你的go程序来说就是一个虚拟内核

每个P会分配一个**OS线程（M）**。M代表machine。这个线程是OS来处理的，并且OS还负责把线程放置到一个core上去执行。

每个Go程序同时也会有一个初始的**Goroutine（G）**。一个Goroutine本质上是一个协程[（Coroutine）](https://en.wikipedia.org/wiki/Coroutine)，但是在go里，把字面“C”替换为“G”所以我们叫Goroutine。你可以认为Goroutine是一个用户程序级别的线程而且它跟OS线程很多方面都类似。区别仅仅是OS线程在内核(Core)上进行上下文切换，而Goroutines是在M上。

### 2.2 协作调度

我们在第一部分的内容讲到了，OS调度器是一个抢占式调度器。也就是说你不知道调度器下一步会执行什么。内核所做的决定都是不确定的。运行在OS顶层的应用程序无法控制内核里面的调度，除非你使用同步的原始操作，例如[`atomic`](https://en.wikipedia.org/wiki/Linearizability)指令和[`mutex`](https://en.wikipedia.org/wiki/Lock_(computer_science))调用

Go调度器是Go runtime的一部分，Go runtime会编译到你应用程序里。这意味着Go调度器运行在内核之上的[用户空间(user space)](https://en.wikipedia.org/wiki/User_space)

当前Go调度器采用的不是抢占式调度器，而是[协作试](https://en.wikipedia.org/wiki/Cooperative_multitasking)调度器。协作试调度器，意味着调度器需要代码中安全点处发生的定义好的用户空间事件去做出调度决策。

Go的协作调度有一个非常棒的地方就是，它看上去像是抢占式的。你没办法预测Go调度器将要做什么，调度决策不是开发人员而是go runtime去做的。将Go调度器看做是一个抢占式调度器是很重要的，因为调度是不确定的，这里不需要再过多延伸。

### 2.3 Goroutine状态

和线程一样。Goroutine有三种相同的高级状态。Goroutine可以是任何一种状态：等待（Waiting）、可执行（Runnable）、运行中（Executing）.

等待：此时Goroutine已经停止并且等待事件发生然后再次执行。这可能是出于等待操作系统（系统调用）或同步调用（原子操作atomic和互斥操作mutex）等原因。 这些类型的延迟是性能不佳的根本原因。

可执行： 此时Goroutine想要在M上执行分配给它的指令。如果有很多Goroutines想要M上的时间片，那么Goroutines必须等待更长时间。而且，随着更多Goroutines争夺时间片，单独Goroutines分配的时间就会缩短，这种类型的调度延时也会导致性能很差。

运行中：这意味着Goroutines已经放置在M上并且执行它的指令。此时应用程序的工作即将完成，这是我们想要的状态。

### 2.4  上下文切换（Context Switching）

Go调度程序需要明确定义的用户空间事件，这些事件发生在代码中的安全点以进行上下文切换。这些事件和安全点在函数调用时发生。函数调用对Go调度器的运行状况至关重要。Go 1.11 或者更低版本中，如果你跑一个不做函数调用的死循环，会导致调度器延时和垃圾回收延时。合理的时机使用函数调用十分重要。

##### 注意：[相关issue和建议](https://github.com/golang/go/issues/24543)已经被提出来，并且应用到了1.12版本中。应用非协作的抢占式技术，使得在tight loop中进行抢占。

Go程序中有4种类型的事件，允许调度器去做出调度决策。

- 使用关键字 go
- 垃圾回收
- 系统调用
- 同步处理

### 2.5 异步系统调用

当OS有能力去处理异步的系统调用时候，使用[网络轮询器(network poller)](https://golang.org/src/runtime/netpoll.go)去处理系统调用会更加高效。不同的操作系统分别使用了kqueue (MacOS)、epoll (Linux) 、 iocp (Windows) 对此作了实现。

今天许多操作系统都能处理基于网络(Networking-based)的系统调用。这也是网络轮询器(network poller)这一名字的由来，因为它的主要用途就是处理网络操作。网络系统上通过使用network poller，调度器可以防止Goroutines在系统调用的时候阻塞M。这可以让M能够去执行P的 LRQ上面的其他Goroutines，而不是再去新建一个M。这可以减少OS上的调度加载。

### 2.6 同步系统调用

当Goroutine想进行系统调用无法异步进行该怎么办呢？这种情况下，无法使用 network poller并且Goroutine产生的系统调用会阻塞M。很不幸但是我们无法阻止这种情况发生。一个例子就是基于文件的系统调用。如果你使用CGO，当你调用C函数的时候也会有其他情况发生会阻塞M。

###### 注意：Windows操作系统确实有能力去异步进行基于文件的系统调用。从技术上讲，在Windows上运行时可以使用network poller。

### 2.7工作窃取（Work Stealing）

从另一个层面看，调度器的工作方式其实是work-stealing的。这种行为在一些情况下能够让调度更有效率。我们最不想看到的事情是一个M进入了等待状态，因为这一旦发生，OS将会把M从core上切换下来。这意味着即使有可执行的Goroutine， P此时也没法干活了，直到M重新切换回core上。Work stealing同时也会平衡P上的所有Goroutines从而能够使工作更好的分配，更有效率。

[Work Stealing](https://golang.org/src/runtime/proc.go)的规则如下

###### L2

```
runtime.schedule() {
    // only 1/61 of the time, check the global runnable queue for a G.
    // if not found, check the local queue.
    // if not found,
    //     try to steal from other Ps.
    //     if not, check the global runnable queue.
    //     if not found, poll network.
}
复制代码
```

所以基于L2的规则，P1需要去看P2的LRQ上的Goroutines并且拿走一半。这种work stealing的很大好处是，它让M一直有事情做而不是闲下来。这种work stealing 可以看做内部的M的轮转，这种轮转的好处在[这篇博客](https://rakyll.org/scheduler/)里做了很好的解释。

### 2.8 上下文切换cost

 所有的上下文切换(context switches)和状态的改变都需要花费时间去处理，这就限制了工作速度。每一次上下文切换
会导致50ns的潜在延迟，硬件执行指令的期望时间是每ns 12个指令，你会看到上下文切换的时候就少执行600个指令。因为这些线程在不同的core之前切来切去，cache-line未命中导致的延迟也会增加

  在使用Goroutines的场景，整个过程一直使用的是相同的OS线程和Core。这也就意味着，从OS的视角，OS线程从来没有进入到waiting状态，一次也没有。结果就是我们在线程中上下文切换丢失的指令在Goroutines中不会丢失。

本质上讲，在OS层级go把io/blocking类型的工作转变成了cpu密集型的工作。由于所有上下文切换的过程都发生在应用程序的级别，上下文切换不会像线程一样丢掉600个指令（平均来说）。Go调度器还有助于提高cache-line的效率和[NUMA](http://frankdenneman.nl/2016/07/07/numa-deep-dive-part-1-uma-numa)。这也是为什么我们不需要比虚拟内核数更多的线程。在Go里，随着时间推移更多事情会被处理，因为Go调度器会尝试用更少的线程并且每个线程去做更多事情，这有助于减少OS和硬件层级的加载延迟。

### 2.9 结论

Go调度程序的设计在考虑操作系统和硬件工作复杂性方面确实令人惊讶。 在操作系统级别将IO /blocking工作转换为CPU密集型工作，是在利用更多CPU容量的过程中获得巨大成功的地方。 这就是为什么你不需要比虚拟内核数更多的OS线程。 每个虚拟内核一个OS线程情况下，你可以合理的期望你的所有工作(CPU密集、IO密集)都能够完成。对于网络程序和那些不需要系统调用阻塞OS线程的程序，也能够完成。

作为开发人员，你依旧需要理解在处理不同类型工作的时候你的程序正在做什么。你不能为了想要更好性能去无限制创建goroutine。Less is always more，但是通过理解了go调度器，你可以更好的做出决定。下一部分，我会探讨以保守的方式利用并发来提升性能的方法，但是对于代码的复杂性还是要做出平衡。

## 三、并发

### 3.1 什么是并发

并发的含义就是**无序的执行**。给你一系列的指令，去找到一个方式可以无序执行而且和有序执行产生同样的结果。这个问题在你面前，显而易见的是无序执行会增加一些足够的性能增益在计算了复杂性成本之后，但是你可能会觉得无序执行是不可能的甚至是没有意义的。

你也要清楚一点，[并发和并行是不一样的](https://blog.golang.org/concurrency-is-not-parallelism)。并行是在相同时间内同时执行两个或两个以上的指令，这和并发的概念不一样。

### 3.2  工作负载(workloads)

你是如何知道无序执行(并发)是可行的呢？了解你所处理问题的工作负载(workload)是一个起点。有两种类型的工作负载在并发的时候要考虑到。

- **CPU密集(CPU-Bound)**：这种工作负载情况不会有Goroutines自动切换到waiting状态的情况，也不会有自动从waiting状态切到其他状态的情况。这种情况发生在进行持续计算的时候。线程计算Pi值就是CPU-Bound。
- **IO密集(IO-Bound)**：这种工作负载会导致Goroutines自动进入等待状态。这种工作发生在持续地请求网络资源、或者是进行系统调用、或者是等待事件发生的情况。一个Goroutines需要读文件就是IO-Bound。我把同步事件(mutexes，atomic)类似导致Goroutine等待的情况归到此类。


冒泡排序在使用并发时不会有性能提升，反而有所下降。因为冒泡排序的本质就是遍历整个list。  

### 3.3 结论

这篇文章的目的就是让你知道什么时候你的workload适合使用并发。考虑到不同的场景，我给出了不同的例子。

你可以清楚的看到IO-Bound类型的workload并不需要使用并行处理去获得性能的大幅增加，这正好跟CPU-Bound类型的工作截然相反。像类似冒泡算法这种，使用并发其实会增加代码复杂度，而且不会有任何性能增益。所以，一定要确定你的workload是否适合使用并发场景，这是很重要的事情。